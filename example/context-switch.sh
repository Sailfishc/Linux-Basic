
# 以 10 个线程运行 5 分钟的基准测试，模拟多线程切换的问题
sysbench --threads=10 --max-time=300 threads run


# 查看vmstat
# 每隔1 秒输出 1 组数据(需要 Ctrl+C 才结束)
vmstat 1

#procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
# r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
#11  0      0 239652 182984 2564392    0    0     0    11    2    3  1  1 99  0  0
#10  0      0 239628 182984 2564392    0    0     0     0 4406 1717485 19 80  1  0  0
# 7  0      0 239604 182984 2564392    0    0     0     0 4142 1690664 18 82  1  0  0
# 6  0      0 239628 182984 2564392    0    0     0     0 4259 1674882 21 79  1  0  0
# 8  0      0 239256 182984 2564392    0    0     0     0 4852 1648981 21 78  1  0  0
# 7  0      0 239256 182984 2564392    0    0     0     0 4285 1698305 21 79  1  0  0
# 7  0      0 239256 182984 2564396    0    0     0     0 4307 1737860 19 80  1  0  0
# 8  0      0 239256 182984 2564396    0    0     0     0 4323 1685005 20 80  1  0  0
# 6  0      0 239008 182984 2564396    0    0     0     0 4621 1666960 20 80  1  0  0
# 9  0      0 239008 182984 2564396    0    0     0     0 3819 1693558 20 79  1  0  0
# 9  0      0 239224 182984 2564396    0    0     0     0 4109 1704840 19 81  1  0  0
# 5  0      0 239224 182984 2564396    0    0     0     0 4268 1714169 20 80  1  0  0
# 7  0      0 238976 182984 2564396    0    0     0     0 4413 1712454 21 79  1  0  0

# 现象：cs 列的上下文切换次数从之前的 35 骤然上升到了 172 万
# r 列:就绪队列的长度已经到了 8，远远超过了系统 CPU 的个数 2，所以肯定会有大量 的 CPU 竞争。
# us(user)和 sy(system)列:这两列的 CPU 使用率加起来上升到了 100%，其中系 统 CPU 使用率，也就是 sy 列高达 84%，说明 CPU 主要是被内核占用了。
# in 列:中断次数也上升到了 1 万左右，说明中断处理也是个潜在的问题。

# 结论：综合这几个指标，我们可以知道，系统的就绪队列过长，也就是正在运行和等待 CPU 的进 程数过多，
# 导致了大量的上下文切换，而上下文切换又导致了系统 CPU 的占用率升高。


# 每隔 1 秒输出 1 组数据(需要 Ctrl+C 才结束)
# -w 参数表示输出进程切换指标，而 -u 参数则表示输出 CPU 使用指标
pidstat -w -u 1

#通过pidstat可以发现CPU 使用率的升高果然是 sysbench 导致的，它的 CPU 使 用率已经达到了 100%
#Linux 调度的基本单位实际上是线程，而我们的场景 sysbench 模拟的也是线程 的调度问题，pidstat默认打印的是进程，所以需要添加参数输出线程指标

# -wt 参数表示输出线程的上下文切换指标
# 每隔 1 秒输出一组数据
pidstat -wt 1


# 除了上下文切换频率骤然升高， 还有一个指标也有很大的变化。是的，正是中断次数。
# 中断次数也上升到了 1 万，但到底 是什么类型的中断上升了，现在还不清楚。我们接下来继续抽丝剥茧找源头。
#中断，我们都知道，它只发生在内核态，而 pidstat 只是一个进程的性能分析工具， 并不提供任何关于中断的详细信息，怎样才能知道中断发生的类型呢?
# 查看/proc/interrupts文件
# -d 参数表示高亮显示变化的区域
watch -d cat /proc/interrupts

#变化速度最快的是重调度中断(RES)，这个中断类型表示， 唤醒空闲状态的 CPU 来调度新的任务运行。
# 这是多处理器系统(SMP)中，调度器用来分 散任务到不同 CPU 的机制，通常也被称为处理器间中断(Inter-Processor Interrupts， IPI)。


# 总结
#自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题;
#非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈;
#中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文 件来分析具体的中断类型。
